# ğŸ§  Detecting AI-Generated Text Using Statistical and Linguistic Features

A machine learning project to classify whether a given text is **AI-generated** or **Human-written**, using **statistical**, **linguistic**, and **TF-IDF**-based features. This solution integrates classical feature engineering with machine learning for high accuracy on a large-scale dataset.

---

## ğŸ“Œ Table of Contents

* [ğŸš€ Project Overview](#-project-overview)
* [ğŸ“ Dataset](#-dataset)
* [ğŸ” Exploratory Data Analysis](#-exploratory-data-analysis)
* [ğŸ§ª Feature Engineering](#-feature-engineering)
* [ğŸ“Š Feature Selection](#-feature-selection)
* [ğŸ¤– Modeling & Evaluation](#-modeling--evaluation)
* [ğŸ’¾ Model Saving](#-model-saving)
* [ğŸ“ˆ Results](#-results)
* [ğŸ”® Future Work](#-future-work)
* [ğŸ“¦ Requirements](#-requirements)
* [ğŸ“ License](#-license)

---

## ğŸš€ Project Overview

The main objective of this project is to develop a machine learning pipeline that can accurately distinguish between **human-authored** and **AI-generated** text using:

* **Engineered linguistic/statistical features**
* **TF-IDF text vectorization**
* **Classical machine learning models** (Logistic Regression, Random Forest)

---

## ğŸ“ Dataset

ğŸ“Œ **Source**: [Kaggle â€“ AI vs Human Text Dataset](https://www.kaggle.com/datasets/shanegerami/ai-vs-human-text/data)

* Total samples used: **100,000**

  * 50,000 AI-generated
  * 50,000 Human-written
* Format: `.csv` file with `text` and `generated` columns
  (`generated`: 0 = Human, 1 = AI)

---

## ğŸ” Exploratory Data Analysis

Performed extensive EDA:

* Checked class balance, duplicates, nulls
* Explored:

  * Character/word counts
  * Class distributions
  * Histogram visualizations per class

---

## ğŸ§ª Feature Engineering

Extracted **14 custom features** from each text sample:

| Type               | Features                                                        |
| ------------------ | --------------------------------------------------------------- |
| Text Statistics    | `char_count`, `word_count`, `avg_word_len`                      |
| Punctuation        | `punct_count`, `exclam_count`, `quest_count`                    |
| Style Metrics      | `digit_ratio`, `upper_ratio`, `stopword_ratio`                  |
| Readability Scores | `flesch_reading_ease`, `flesch_kincaid_grade`                   |
| Vocabulary         | `lexical_diversity`                                             |
| Social Indicators  | `url_count`, `mention_count`, `hashtag_count`, `html_tag_count` |

All features were normalized using **MinMaxScaler**.

---

## ğŸ“Š Feature Selection

* Used **ANOVA F-test (`SelectKBest`)** for univariate feature selection.
* Chose top 10 informative features based on F-score.
* Also visualized a **correlation heatmap** to check feature redundancy.

---

## ğŸ¤– Modeling & Evaluation

**Combined Features Used**:

* **TF-IDF** (10,000 features from unigrams & bigrams)
* **Top 10 engineered features**

**Models Trained**:

* âœ… Logistic Regression (baseline)
* âœ… Random Forest Classifier (ensemble)

Each model was evaluated with:

* Classification Report (precision, recall, F1-score)
* Confusion Matrix
* Accuracy and F1 Score comparison

---

## ğŸ’¾ Model Saving

Saved trained models using `joblib` for future use:

* `random_forest_model.pkl`
* `logistic_regression_model.pkl`

---

## ğŸ“ˆ Results

| Model               | Accuracy | F1 Score |
| ------------------- | -------- | -------- |
| **Random Forest**   | âœ… High   | âœ… Best   |
| Logistic Regression | Good     | Good     |

**Random Forest** showed stronger performance, benefiting from mixed feature types and ensemble structure.

---

## ğŸ”® Future Work

Planned extensions and enhancements:

* Integrate **transformer models** like BERT for deeper semantic understanding.
* Extend support for **multilingual texts**.
* Add **adversarial AI-generated samples** to improve robustness.
* Apply **explainability tools** like SHAP or LIME.

---

## ğŸ“¦ Requirements

Install dependencies with:

```bash
pip install -r requirements.txt
```

**Main Libraries Used**:

* `pandas`, `numpy`
* `scikit-learn`
* `matplotlib`, `seaborn`
* `joblib`, `re`, `string`

---

## ğŸ“ License

This project is licensed under the **MIT License**.
See the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

Special thanks to:

* Kaggle dataset authors
* Open-source contributors
* Community feedback

---

> ğŸ“¢ *Have feedback or suggestions? Please open an issue or submit a pull request!*

---
